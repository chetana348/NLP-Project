{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb9db2bb",
   "metadata": {},
   "source": [
    "The code here is adapted from the brev.dev Mistral fine-tuning tutorial by Harper Caroll at\n",
    "\n",
    "https://github.com/brevdev/notebooks/blob/main/mistral-finetune-own-data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ce2e2",
   "metadata": {},
   "source": [
    "Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb7ff37-34ea-48bb-9eb5-db1ef8bc76c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only if pytorch needs to be installed in your conda env\n",
    "!conda install --yes pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a21228b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /home/oblaat/.local/lib/python3.11/site-packages (0.41.2.post2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b9cddd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - pytorch\n",
      " - nvidia\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a5b394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe064ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592f639a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - pytorch\n",
      " - nvidia\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e89cae21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - pytorch\n",
      " - nvidia\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a16a1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - pytorch\n",
      " - nvidia\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7578ebdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - pytorch\n",
      " - nvidia\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02031f4-fa70-42be-9e24-5fcf4b3738db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589729bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "627ead37-5ebd-4d42-b020-b6d1a8f26aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1 /home/oblaat/.conda/envs/jack_conda_env/lib/python3.11/site-packages/torch/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__, torch.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f1003f-b895-40a6-84b8-734527a18bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file paths where we are going to store our results\n",
    "filename_template = \"results_struct_prompt/{num1}_digit/{num2}_digit/t_{idx:02}.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e3152c-8152-45ae-9ed3-ba42007023ee",
   "metadata": {},
   "source": [
    "WARNING: you need at least 16GB CPU RAM for this step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "978af1dc-c1db-4328-a677-f747412522be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53cffbc16564855b1c4cf8d18df72c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load base model - mistralai/Mistral-7B-Instruct-v0.1 - using 4-bit quantization\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23bfb9fa-3af8-436a-af99-4bb35343f86b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11e0480c-0702-4e65-9dd5-0199e5a352e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test base Mistral on an example\n",
    "eval_prompt = \" Answer the following:\\n38 + 11\\na:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15743603-a17d-4912-9365-177f8d738c34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Answer the following:\n",
      "38 + 11\n",
      "a: 49\n"
     ]
    }
   ],
   "source": [
    "# Re-init the tokenizer so it doesn't add padding or eos token\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5cb26",
   "metadata": {},
   "source": [
    "Some functions to help with batch testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "819dd50f-6d84-4fdc-aa7b-83949f12fa96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions for generating random n-digit numbers\n",
    "def generate_random_n_digit_number(n):\n",
    "    \"\"\"\n",
    "    Generates a random n-digit number.\n",
    "\n",
    "    :param n: Number of digits in the number.\n",
    "    :return: A random n-digit number.\n",
    "    \"\"\"\n",
    "    # Ensure the first digit is not zero\n",
    "    first_digit = random.randint(1, 9)\n",
    "\n",
    "    # Generate the remaining n-1 digits, which can include zero\n",
    "    remaining_digits = [random.randint(0, 9) for _ in range(n - 1)]\n",
    "\n",
    "    # Combine the digits to form the number\n",
    "    digits = [first_digit] + remaining_digits\n",
    "    return int(''.join(map(str, digits)))\n",
    "\n",
    "def get_random_pair(used_pairs: set, i: int, j: int) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Get pair of random numbers\n",
    "    \n",
    "    :param used_pairs: A set of all pairs of numbers used so far\n",
    "    :param i: length in digits of first number\n",
    "    :param j: length in digits of second number\n",
    "    :return: A tuple of 2 numbers\n",
    "    \"\"\"\n",
    "    nums_used = True\n",
    "    while nums_used:\n",
    "        num1 = generate_random_n_digit_number(i)\n",
    "        num2 = generate_random_n_digit_number(j)\n",
    "        pair = (num1, num2)\n",
    "        nums_used = pair in used_pairs\n",
    "    used_pairs.add(pair)\n",
    "    return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b138c0e5-2afc-450c-a596-9672e134402f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "def extract_numbers_from_string(content):\n",
    "    \"\"\"\n",
    "    Extract the two operands and the result from answer string.\n",
    "    \n",
    "    :param content: response from the LLM as a string\n",
    "    :return: A tuple with operand 1, operand 2, and addition result\n",
    "    \"\"\"\n",
    "    # Regex patterns to match numbers in the specified format\n",
    "    addition_pattern = r'\\n\\nInput:\\nNumber 1: (\\d+),\\s*Number 2: (\\d+)'\n",
    "    a_number_pattern = r'(\\d+)\\.$'\n",
    "    \n",
    "    # Find and extract numbers for the addition\n",
    "    addition_match = re.search(addition_pattern, content)\n",
    "    if addition_match:\n",
    "        num1, num2 = addition_match.groups()\n",
    "    else:\n",
    "        num1, num2 = None, None\n",
    "\n",
    "    # Find and extract the number given for the final answer\n",
    "    a_number_match = re.search(a_number_pattern, content)\n",
    "    if a_number_match:\n",
    "        a_number = a_number_match.group(1)\n",
    "    else:\n",
    "        a_number = None\n",
    "\n",
    "    return int(num1), int(num2), int(a_number)\n",
    "\n",
    "\n",
    "def run_problem(prompt):\n",
    "    \"\"\"\n",
    "    get result of running the prompt through the LLM as a string\n",
    "    \"\"\"\n",
    "    eval_prompt = prompt\n",
    "    model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        response = tokenizer.decode(model.generate(**model_input, max_new_tokens=650, repetition_penalty=1.15)[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c4f655",
   "metadata": {},
   "source": [
    "One example to make sure those functions work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cad5a19b-3f71-4424-8bdf-ee47d5f75bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform the calculation: Add two numbers by breaking the task into smaller parts. Decompose this addition into smaller parts, adding each corresponding set of digits separately. Show each step of your calculation clearly, and provide the final sum as a single, definitive answer. Ensure that each step is accurately calculated and presented in a clear, orderly manner. An example of this task is shown here:\n",
      "\n",
      "BEGIN EXAMPLE\n",
      "Input:\n",
      "Number 1: 695142, Number 2: 3876\n",
      "\n",
      "Response:\n",
      "To calculate the sum of 695142 and 3876, we will align the digits correctly and decompose the addition into smaller parts. The numbers aligned are:\n",
      "\n",
      "695142\n",
      "+  3876\n",
      "------\n",
      "The process of calculating each subtotal is as follows:\n",
      "\n",
      "Units place: 2 (from 695142) + 6 (from 3876) = 8\n",
      "Tens place: 4 (from 695142) + 7 (from 3876) = 11 (carry 1 to the next place)\n",
      "Hundreds place: 1 (from 695142) + 8 (from 3876) + 1 (carried over) = 10 (carry 1 to the next place)\n",
      "Thousands place: 5 (from 695142) + 3 (from 3876) + 1 (carried over) = 9\n",
      "Ten-thousands place: 9 (from 695142) = 9 (no corresponding digit in 3876)\n",
      "Hundred-thousands place: 6 (from 695142) = 6 (no corresponding digit in 3876)\n",
      "Now, we add the subtotals together to find the final sum:\n",
      "\n",
      "Units place: 8\n",
      "Tens place: 10\n",
      "Hundreds place: 100\n",
      "Thousands place: 9000\n",
      "Ten-thousands place: 90000\n",
      "Hundred-thousands place: 600000\n",
      "Adding these subtotals together:\n",
      "8 + 10 + 100 + 9000 + 90000 + 600000 = 699018\n",
      "\n",
      "Therefore, the sum of 695142 and 3876 is 699018.\n",
      "END EXAMPLE\n",
      "\n",
      "Add the following two numbers as shown in the example:\n",
      "\n",
      "Input:\n",
      "Number 1: 768091, Number 2: 6023\n",
      "\n",
      "Response:\n",
      "\n",
      "Perform the calculation: Add two numbers by breaking the task into smaller parts. Decompose this addition into smaller parts, adding each corresponding set of digits separately. Show each step of your calculation clearly, and provide the final sum as a single, definitive answer. Ensure that each step is accurately calculated and presented in a clear, orderly manner. An example of this task is shown here:\n",
      "\n",
      "BEGIN EXAMPLE\n",
      "Input:\n",
      "Number 1: 695142, Number 2: 3876\n",
      "\n",
      "Response:\n",
      "To calculate the sum of 695142 and 3876, we will align the digits correctly and decompose the addition into smaller parts. The numbers aligned are:\n",
      "\n",
      "695142\n",
      "+  3876\n",
      "------\n",
      "The process of calculating each subtotal is as follows:\n",
      "\n",
      "Units place: 2 (from 695142) + 6 (from 3876) = 8\n",
      "Tens place: 4 (from 695142) + 7 (from 3876) = 11 (carry 1 to the next place)\n",
      "Hundreds place: 1 (from 695142) + 8 (from 3876) + 1 (carried over) = 10 (carry 1 to the next place)\n",
      "Thousands place: 5 (from 695142) + 3 (from 3876) + 1 (carried over) = 9\n",
      "Ten-thousands place: 9 (from 695142) = 9 (no corresponding digit in 3876)\n",
      "Hundred-thousands place: 6 (from 695142) = 6 (no corresponding digit in 3876)\n",
      "Now, we add the subtotals together to find the final sum:\n",
      "\n",
      "Units place: 8\n",
      "Tens place: 10\n",
      "Hundreds place: 100\n",
      "Thousands place: 9000\n",
      "Ten-thousands place: 90000\n",
      "Hundred-thousands place: 600000\n",
      "Adding these subtotals together:\n",
      "8 + 10 + 100 + 9000 + 90000 + 600000 = 699018\n",
      "\n",
      "Therefore, the sum of 695142 and 3876 is 699018.\n",
      "END EXAMPLE\n",
      "\n",
      "Add the following two numbers as shown in the example:\n",
      "\n",
      "Input:\n",
      "Number 1: 768091, Number 2: 6023\n",
      "\n",
      "Response:\n",
      "To calculate the sum of 768091 and 6023, we will align the digits correctly and decompose the addition into smaller parts. The numbers aligned are:\n",
      "\n",
      "768091\n",
      "+  6023\n",
      "------\n",
      "The process of calculating each subtotal is as follows:\n",
      "\n",
      "Units place: 1 (from 768091) + 0 (from 6023) = 1\n",
      "Tens place: 6 (from 768091) + 0 (from 6023) = 6\n",
      "Hundreds place: 7 (from 768091) + 0 (from 6023) = 7\n",
      "Thousands place: 6 (from 768091) + 0 (from 6023) = 6\n",
      "Ten-thousands place: 8 (from 768091) = 8 (no corresponding digit in 6023)\n",
      "Hundred-thousands place: 0 (from 768091) = 0 (no corresponding digit in 6023)\n",
      "Now, we add the subtotals together to find the final sum:\n",
      "\n",
      "Units place: 1\n",
      "Tens place: 6\n",
      "Hundreds place: 7\n",
      "Thousands place: 6\n",
      "Ten-thousands place: 8\n",
      "Hundred-thousands place: 0\n",
      "Adding these subtotals together:\n",
      "1 + 6 + 7 + 6 + 8 + 0 = 28\n",
      "\n",
      "Therefore, the sum of 768091 and 6023 is 28.\n",
      "768091 6023 28 False\n"
     ]
    }
   ],
   "source": [
    "used_pairs = set()\n",
    "num1, num2 = get_random_pair(used_pairs, 6, 4)\n",
    "with open(\"prompt_6_4.txt\") as f:\n",
    "    prompt_template = f.read()\n",
    "prompt = prompt_template.format(num1=num1, num2=num2)\n",
    "print(prompt)\n",
    "response = run_problem(prompt)\n",
    "print(response)\n",
    "_, _, answer = extract_numbers_from_string(response)\n",
    "print(num1, num2, answer, answer == (num1 + num2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5aeb94d3-8418-464c-b68d-65d028a79da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59e80130-3ffd-4b26-9dbc-7a7de90d8d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_trials = 5  # The first time I ran these tials I used 50 as num_trials here, using 5 now for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d906ff7d-9b22-467c-a2ba-ffa69a2758f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124753 166453 46 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132577 383107 45 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784510 514272 902222 False\n"
     ]
    }
   ],
   "source": [
    "# i - number of LHS digits we'll use\n",
    "results = {}\n",
    "for i in [6]:\n",
    "    # j - number of RHS digits - we'll go from 1 to 6\n",
    "    results[i] = defaultdict(list)\n",
    "    for j in range(1, 7):\n",
    "        used_pairs = set()\n",
    "        with open(f\"prompt_{i}_{j}.txt\") as f:\n",
    "            prompt_template = f.read()\n",
    "        for k in range(num_trials):\n",
    "            num1, num2 = get_random_pair(used_pairs, i, j)\n",
    "            prompt = prompt_template.format(num1=num1, num2=num2)\n",
    "            response = run_problem(prompt)\n",
    "            _, _, answer = extract_numbers_from_string(response)\n",
    "            is_correct = answer == (num1 + num2)\n",
    "            results[i][j].append((num1, num2, answer, is_correct))\n",
    "            if k % 2 == 0:\n",
    "                print(num1, num2, answer, is_correct)\n",
    "            filename = filename_template.format(num1=i, num2=j, idx=k)\n",
    "            directory = os.path.dirname(filename)\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            with open(filename, 'w') as f_out:\n",
    "                f_out.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb704b",
   "metadata": {},
   "source": [
    "Now for the batch testing. We'll test for 6 digit LHS, and 1-6 digits RHS. 100 trials for each RHS digit length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84d5301",
   "metadata": {},
   "source": [
    "Now the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ba357e9-bbe4-46af-8e6d-2afb84649742",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6: 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "for i in [6]:\n",
    "    accuracies = []\n",
    "    for j in range(1, i+1):\n",
    "        num_correct = 0\n",
    "        for k in range(num_trials):\n",
    "            filename = filename_template.format(num1=i, num2=j, idx=k)\n",
    "            #print(i, j, k, filename)\n",
    "            with open(filename, 'r') as f:\n",
    "                content = f.read()\n",
    "            num1, num2, answer = extract_numbers_from_string(content)\n",
    "            is_correct = int(num1) + int(num2) == int(answer)\n",
    "            #print(num1, num2, answer, is_correct)\n",
    "            if is_correct:\n",
    "                num_correct += 1\n",
    "        accuracies.append(num_correct)\n",
    "    accuracies = [(float(x) / num_trials) * 100 for x in accuracies]\n",
    "    str_acc = [str(int(x)) for x in accuracies]\n",
    "    print(f\"{i}: {' '.join(str_acc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f260b4df-d4e5-4f95-94d4-6001b250611a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE the first time I ran this I got 6: [26, 14, 8, 0, 0, 0] for the accuracies, this is what is reflected in the chart on the poster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02767f88-3bc0-4be8-9011-d98cb968be8b",
   "metadata": {},
   "source": [
    "Disappointing results to say the least. Not only did this not improve our accuracy, but it got much worse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e695f711-3a12-4818-9b1e-f502e271a09e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:.conda-jack_conda_env]",
   "language": "python",
   "name": "conda-env-.conda-jack_conda_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
