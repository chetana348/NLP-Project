{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f50b8d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4041194c",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "###### Generate an addition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73d9c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([tensor([15,  5,  1, 10,  9,  2, 13,  1,  4,  3, 14]), tensor([15,  1,  4, 10,  7,  1, 13,  8,  5, 14]), tensor([15,  6,  0, 10,  2,  0, 13,  8,  0, 14]), tensor([15,  8,  2, 10,  8,  6, 13,  1,  6,  8, 14])], ['51+92=143', '14+71=85', '60+20=80', '82+86=168'])\n",
      "([tensor([15,  7,  4, 10,  7,  4, 13,  1,  4,  8, 14]), tensor([15,  8,  7, 10,  9,  9, 13,  1,  8,  6, 14]), tensor([15,  2,  3, 10,  0,  2, 13,  2,  5, 14]), tensor([15,  2,  1, 10,  5,  2, 13,  7,  3, 14])], ['74+74=148', '87+99=186', '23+02=25', '21+52=73'])\n"
     ]
    }
   ],
   "source": [
    "PLUS_SIGN = 10\n",
    "MUL_SIGN  = 11\n",
    "MINUS_SIGN = 12\n",
    "EQUAL_SIGN = 13\n",
    "EOS = 14\n",
    "BOS = 15\n",
    "PAD = 16\n",
    "UNK = 17\n",
    "\n",
    "symbol_to_int_dict = {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4,\n",
    "                      \"5\": 5, \"6\": 6, \"7\": 7, \"8\": 8, \"9\": 9,\n",
    "                      \"+\": PLUS_SIGN, \"*\": MUL_SIGN, \"-\": MINUS_SIGN,\n",
    "                      \"=\": EQUAL_SIGN,  \"<EOS>\": EOS, \"<BOS>\": BOS,\n",
    "                      \"<pad>\": PAD, \"??\": UNK\n",
    "                      }\n",
    "\n",
    "int_to_symbol_dict = {y:x for (x,y) in symbol_to_int_dict.items()}\n",
    "vocab_size = len(symbol_to_int_dict)\n",
    "\n",
    "def decode_equation(equation):\n",
    "    '''convert an equation in list format to string format '''\n",
    "    res = \"\".join([str(int_to_symbol_dict.get(x, UNK)) for x in equation.tolist()])\n",
    "    return res.replace(\"<BOS>\", \"\").replace(\"<EOS>\", \"\")\n",
    "\n",
    "def encode_equation(equation, max_ndigits, padQ=True):\n",
    "    '''convert an equation(up to the equal sign in it) in string format to a list'''\n",
    "    equal_size_loc = equation.index('=')\n",
    "    plus_size_loc = equation.index('+')\n",
    "    num1 = pad_number(equation[0:plus_size_loc], max_ndigits)\n",
    "    num2 = pad_number(equation[plus_size_loc+1:equal_size_loc], max_ndigits)\n",
    "    new_equation = num1 + \"+\" + num2 + \"=\"\n",
    "    return torch.tensor([BOS]+[symbol_to_int_dict.get(n, UNK) for n in new_equation]).to(DEVICE)\n",
    "\n",
    "\n",
    "def pad_number(num, max_ndigits)->str:\n",
    "    'pad numbers with zeros in front so that they have the same length max_ndigits'\n",
    "    s = str(num)\n",
    "    while len(s)<max_ndigits:\n",
    "      s = \"0\"+s\n",
    "    return s\n",
    "\n",
    "def create_add_dataset(max_ndigits, dataset_size, padQ=True):\n",
    "    ''' Function for creating an addition dataset.\n",
    "    if padQ=True, pre-padding of 0s will be added on the numbers such that all the \n",
    "    numbers has the same length max_ndigits, for example, with max_ndigits=3,  \n",
    "    32 will be represented 032.\n",
    "    '''\n",
    "    dataset_str = []\n",
    "    for i in range(dataset_size):\n",
    "        num1, num2 = np.random.randint(0, 10**max_ndigits, 2)\n",
    "        ans = num1 + num2\n",
    "        # If padQ=True, we pad all the numbers with '0' in front\n",
    "        # such that they all have length max_ndigits\n",
    "        if padQ:\n",
    "            equation = pad_number(num1, max_ndigits) + '+' + pad_number(num2, max_ndigits) + \"=\" + pad_number(ans, max_ndigits)\n",
    "        else:\n",
    "            equation = str(num1) + '+' + str(num2) + \"=\" + str(ans)\n",
    "        dataset_str.append(equation)\n",
    "\n",
    "    dataset = [torch.tensor([BOS]+[symbol_to_int_dict.get(n, UNK) for n in x]+[EOS])\n",
    "               for x in dataset_str]\n",
    "    return dataset, dataset_str\n",
    "\n",
    "print(create_add_dataset(2, 4, padQ=False))\n",
    "print(create_add_dataset(2, 4, padQ=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5962d7e1",
   "metadata": {},
   "source": [
    "# Create dataloders for the train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "946e883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "def pad_sequence(batch):\n",
    "    input_padded = torch.nn.utils.rnn.pad_sequence(batch,\n",
    "                                batch_first=True, padding_value = PAD)\n",
    "    return input_padded\n",
    "\n",
    "@dataclass\n",
    "class DataLoaders:\n",
    "    max_ndigits: int\n",
    "    dataset_size: int\n",
    "    padQ: bool = True\n",
    "    val_loader = None\n",
    "    test_loader = None\n",
    "    train_loader = None\n",
    "\n",
    "    def split_data(self, split=[0.7, 0.1, 0.2]):\n",
    "        # If split consists of floats whose sum is equal to 1 then we split the\n",
    "        # dataset by the percentages given by split. If split contains integers, then\n",
    "        # it is understood that the two first integers in split are the number of examples\n",
    "        # in the validation and test sets.\n",
    "        if isinstance(split[0], float):\n",
    "            train_size  = round(self.dataset_size * split[0])\n",
    "            val_size = round(self.dataset_size * split[1])\n",
    "            test_size = self.dataset_size - train_size - val_size\n",
    "\n",
    "        elif isinstance(split[0], int):\n",
    "            val_size = split[0]\n",
    "            test_size = split[1]\n",
    "            train_size  = dataset_size - test_size - val_size\n",
    "\n",
    "\n",
    "        dataset, _ = create_add_dataset(self.max_ndigits, self.dataset_size, padQ=self.padQ)\n",
    "        train_set, val_set, test_set = torch.utils.data.random_split(dataset,\n",
    "                                                             [train_size, val_size, test_size],\n",
    "                                                    generator=torch.Generator().manual_seed(42) )\n",
    "\n",
    "        self.train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                           shuffle=True, collate_fn = pad_sequence)\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                           shuffle=True, collate_fn=pad_sequence)\n",
    "        self.val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,\n",
    "                                           shuffle=True, collate_fn=pad_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b7c2d7",
   "metadata": {},
   "source": [
    "# GPT model\n",
    "Here is my implementation of the GPT model, including the multi-headed self-attention module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2cfdd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_embed, dropout=0.0):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_embed % h == 0 # check the h number\n",
    "        self.d_k = d_embed//h\n",
    "        self.d_embed = d_embed\n",
    "        self.h = h\n",
    "        self.WQ = nn.Linear(d_embed, d_embed)\n",
    "        self.WK = nn.Linear(d_embed, d_embed)\n",
    "        self.WV = nn.Linear(d_embed, d_embed)\n",
    "        self.linear = nn.Linear(d_embed, d_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x_query, x_key, x_value, mask=None):\n",
    "        nbatch = x_query.size(0) # get batch size\n",
    "        # 1) Linear projections to get the multi-head query, key and value tensors\n",
    "        # x_query, x_key, x_value dimension: nbatch * seq_len * d_embed\n",
    "        # LHS query, key, value dimensions: nbatch * h * seq_len * d_k\n",
    "        query = self.WQ(x_query).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        key   = self.WK(x_key).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        value = self.WV(x_value).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        # 2) Attention\n",
    "        # scores has dimensions: nbatch * h * seq_len * seq_len\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_k)\n",
    "        # 3) Mask out padding tokens and future tokens\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "        # p_atten dimensions: nbatch * h * seq_len * seq_len\n",
    "        p_atten = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        p_atten = self.dropout(p_atten)\n",
    "        # x dimensions: nbatch * h * seq_len * d_k\n",
    "        x = torch.matmul(p_atten, value)\n",
    "        # x now has dimensions:nbtach * seq_len * d_embed\n",
    "        x = x.transpose(1, 2).contiguous().view(nbatch, -1, self.d_embed)\n",
    "        return self.linear(x) # final linear layer\n",
    "\n",
    "\n",
    "class ResidualConnection(nn.Module):\n",
    "  '''residual connection: x + dropout(sublayer(layernorm(x))) '''\n",
    "  def __init__(self, dim, dropout):\n",
    "      super().__init__()\n",
    "      self.drop = nn.Dropout(dropout)\n",
    "      self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "  def forward(self, x, sublayer):\n",
    "      return x + self.drop(sublayer(self.norm(x)))\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    '''Decoder = token embedding + positional embedding -> a stack of N DecoderBlock -> fully-connected layer'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.d_embed = config.d_embed\n",
    "        self.tok_embed = nn.Embedding(config.decoder_vocab_size, config.d_embed)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed))\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.decoder_blocks = nn.ModuleList([DecoderBlock(config) for _ in range(config.N_decoder)])\n",
    "        self.norm = nn.LayerNorm(config.d_embed)\n",
    "        self.linear = nn.Linear(config.d_embed, config.decoder_vocab_size)\n",
    "\n",
    "    def future_mask(self, seq_len):\n",
    "        '''mask out tokens at future positions'''\n",
    "        mask = (torch.triu(torch.ones(seq_len, seq_len, requires_grad=False), diagonal=1)!=0).to(DEVICE)\n",
    "        return mask.view(1, 1, seq_len, seq_len)\n",
    "\n",
    "    def forward(self, input, pad_mask):\n",
    "        seq_len = input.size(1)\n",
    "        trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
    "        x = self.tok_embed(input) + self.pos_embed[:, :input.size(1), :]\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.decoder_blocks:\n",
    "            x = layer( x, trg_mask)\n",
    "        x = self.norm(x)\n",
    "        logits = self.linear(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    ''' EncoderBlock: self-attention -> position-wise feed-forward (fully connected) layer'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.atten = MultiHeadedAttention(config.h, config.d_embed)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(config.d_embed, config.d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.d_ff, config.d_embed)\n",
    "        )\n",
    "        self.residuals = nn.ModuleList([ResidualConnection(config.d_embed, config.dropout)\n",
    "                                       for i in range(2)])\n",
    "\n",
    "    def forward(self, decoder_layer_input, trg_mask):\n",
    "        y = decoder_layer_input\n",
    "        y = self.residuals[0](y, lambda y: self.atten(y, y, y, mask=trg_mask))\n",
    "        return self.residuals[1](y, self.feed_forward)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11427de",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad340b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    decoder_vocab_size: int\n",
    "    d_embed: int\n",
    "    # d_ff is the dimension of the fully-connected  feed-forward layer\n",
    "    d_ff: int\n",
    "    # h is the number of attention head\n",
    "    h: int\n",
    "    N_decoder: int\n",
    "    max_seq_len: int\n",
    "    dropout: float\n",
    "\n",
    "\n",
    "def make_GPT(config):\n",
    "    model = Decoder(config).to(DEVICE)\n",
    "    # initialize model parameters\n",
    "    # it seems that this initialization is very important!\n",
    "    for p in model.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90af9ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch_input(x):\n",
    "        'function for generating model input, target and pad_mask from raw input x'\n",
    "        input = x[:, :-1].to(DEVICE)\n",
    "        equal_sign_loc = [(equation==EQUAL_SIGN).nonzero().item() for equation in x]\n",
    "        # for the target, we mask out the tokens before the equal sign (including the equal sign)\n",
    "        target = [torch.cat(\n",
    "            (torch.tensor([PAD]*equal_sign_loc[i]), x[i][equal_sign_loc[i]+1:])) for i in range(len(x))]\n",
    "        target = torch.cat(target, 0).contiguous().view(-1).to(DEVICE)\n",
    "        pad_mask = (input == PAD).view(input.size(0), 1, 1, input.size(-1))\n",
    "        return input, target, pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db528779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader):\n",
    "    model.train()\n",
    "    grad_norm_clip = 1.0\n",
    "    losses, acc, count = [], 0, 0\n",
    "    num_batches = len(dataloader)\n",
    "    pbar = tqdm(enumerate(dataloader), total=num_batches)\n",
    "    for idx, x  in  pbar:\n",
    "        optimizer.zero_grad()\n",
    "        input, target, pad_mask = make_batch_input(x)\n",
    "        pred = model(input, pad_mask).to(DEVICE)\n",
    "        pred = pred.view(-1, pred.size(-1))\n",
    "        loss = loss_fn(pred, target).to(DEVICE)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        losses.append(loss.item())\n",
    "        # report progress\n",
    "        if idx>0 and idx%50 == 0:\n",
    "            pbar.set_description(f\"ep: {scheduler.last_epoch//num_batches}, train loss={loss.item():.3f},lr={scheduler.get_last_lr()[0]:.5f}\")\n",
    "    return np.mean(losses)\n",
    "\n",
    "def train(model, dataloaders, epochs):\n",
    "    global early_stop_count\n",
    "    train_size = len(dataloaders.train_loader)*batch_size\n",
    "    for ep in range(epochs):\n",
    "        train_loss = train_epoch(model, dataloaders.train_loader)\n",
    "        val_loss = validate(model, dataloaders.val_loader)\n",
    "        print(f'ep {ep}: train_loss: {train_loss:.5f}, val_loss: {val_loss:.5f}')\n",
    "\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def validate(model, dataloder):\n",
    "    'function for computing the loss on the validation set'\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for i, x in enumerate(dataloder):\n",
    "            input, target, pad_mask = make_batch_input(x)\n",
    "            pred = model(input, pad_mask).to(DEVICE)\n",
    "            pred = pred.view(-1, pred.size(-1))\n",
    "            losses.append(loss_fn(pred, target).item())\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c47c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_sum(model, x):\n",
    "    'Function for computing the sum of two numbers.'\n",
    "    for i in range(max_ndigits+2):\n",
    "        pad_mask = (x == PAD).view(1, 1, 1, x.size(-1)).to(DEVICE)\n",
    "        logits = model(x, pad_mask)\n",
    "        last_output = logits.argmax(-1)[:,-1].view(1,1)\n",
    "        x = torch.cat((x, last_output), 1).to(DEVICE)\n",
    "        if last_output.item() == EOS:\n",
    "            break\n",
    "    return x[0]\n",
    "\n",
    "def evaluate(model, dataloader, num_batch=None):\n",
    "    '''Function for evaluation the model.\n",
    "    This function take equations, and truncate them up to the equal-sign, and feed them to the\n",
    "    model to get the predictions, compare them with the correct answers, and output the accuracy.\n",
    "    '''\n",
    "    model.eval()\n",
    "    acc, count = 0, 0\n",
    "    num_wrong_to_display = 5\n",
    "    for idx, x in enumerate(dataloader):\n",
    "        for equation in x:\n",
    "            loc_equal_sign = equation.tolist().index(EQUAL_SIGN)\n",
    "            loc_EOS = equation.tolist().index(EOS)\n",
    "            input = equation[0:loc_equal_sign+1].view(1, -1).to(DEVICE)\n",
    "            ans = equation[:loc_EOS+1].tolist()\n",
    "            ans_pred = compute_sum(model, input)\n",
    "            count += 1\n",
    "\n",
    "            if ans == ans_pred.tolist():\n",
    "                acc +=1\n",
    "            else:\n",
    "                if num_wrong_to_display > 0:\n",
    "                    print(f'correct equation: {decode_equation(equation).replace(\"<pad>\",\"\")}')\n",
    "                    print(f'predicted:        {decode_equation(ans_pred)}')\n",
    "                    num_wrong_to_display -= 1\n",
    "        if num_batch and idx>num_batch:\n",
    "            break\n",
    "    return acc/count\n",
    "\n",
    "def what_is(question:str)->str:\n",
    "    'function for computing the sum of two numbers with input in literal string format'\n",
    "    pred = compute_sum(model, encode_equation(question, max_ndigits).view(1,-1))\n",
    "    pred = decode_equation(pred)\n",
    "    pred = pred[pred.index(\"=\")+1:]\n",
    "    return question+pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b5d9ad",
   "metadata": {},
   "source": [
    "# 2 Digit Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03526ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_size: 271378, train_set_size: 7168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [256, 1, 1, 10], which does not match the required output shape [256, 1, 10, 10]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      " 75%|███████▌  | 21/28 [00:00<00:00, 67.95it/s]/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [88, 1, 1, 10], which does not match the required output shape [88, 1, 10, 10]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "100%|██████████| 28/28 [00:00<00:00, 67.97it/s]\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [232, 1, 1, 10], which does not match the required output shape [232, 1, 10, 10]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: train_loss: 2.50030, val_loss: 1.68551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: train_loss: 1.52802, val_loss: 1.29850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: train_loss: 1.23560, val_loss: 1.04376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: train_loss: 1.02151, val_loss: 0.89575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: train_loss: 0.92378, val_loss: 0.84775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 68.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: train_loss: 0.87335, val_loss: 0.81039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: train_loss: 0.83730, val_loss: 0.78523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 68.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: train_loss: 0.81336, val_loss: 0.74565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: train_loss: 0.77771, val_loss: 0.72891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 68.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: train_loss: 0.75249, val_loss: 0.71506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 68.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: train_loss: 0.72704, val_loss: 0.64269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: train_loss: 0.63846, val_loss: 0.47019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: train_loss: 0.44912, val_loss: 0.26273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: train_loss: 0.31334, val_loss: 0.16070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: train_loss: 0.22283, val_loss: 0.10100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: train_loss: 0.16839, val_loss: 0.06478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: train_loss: 0.12748, val_loss: 0.03534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: train_loss: 0.09619, val_loss: 0.01663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: train_loss: 0.07163, val_loss: 0.01034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: train_loss: 0.05693, val_loss: 0.00651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: train_loss: 0.05116, val_loss: 0.00334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: train_loss: 0.04267, val_loss: 0.00355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: train_loss: 0.03565, val_loss: 0.00313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: train_loss: 0.03339, val_loss: 0.00395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 68.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: train_loss: 0.03013, val_loss: 0.00219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: train_loss: 0.02725, val_loss: 0.00263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: train_loss: 0.02585, val_loss: 0.00189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: train_loss: 0.02414, val_loss: 0.00191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 68.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: train_loss: 0.02031, val_loss: 0.00120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 68.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: train_loss: 0.02168, val_loss: 0.00110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30: train_loss: 0.01743, val_loss: 0.00170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 31: train_loss: 0.01855, val_loss: 0.00299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 68.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: train_loss: 0.01424, val_loss: 0.00272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 33: train_loss: 0.01330, val_loss: 0.00260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 34: train_loss: 0.01315, val_loss: 0.00038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 35: train_loss: 0.01269, val_loss: 0.00161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 36: train_loss: 0.01482, val_loss: 0.00026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 37: train_loss: 0.01232, val_loss: 0.00093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 38: train_loss: 0.00931, val_loss: 0.00194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 39: train_loss: 0.01202, val_loss: 0.00087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 40: train_loss: 0.01197, val_loss: 0.00020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 41: train_loss: 0.00932, val_loss: 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 42: train_loss: 0.00924, val_loss: 0.00061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 43: train_loss: 0.00988, val_loss: 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 44: train_loss: 0.00806, val_loss: 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 45: train_loss: 0.00643, val_loss: 0.00077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 46: train_loss: 0.00778, val_loss: 0.00245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 47: train_loss: 0.00688, val_loss: 0.00188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 48: train_loss: 0.00917, val_loss: 0.00018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 69.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 49: train_loss: 0.00858, val_loss: 0.00225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_ndigits = 2\n",
    "# max_len is determined by 1+ max_ndigits + 1 + max_ndigits + 1 + max_ndigits + 1 + 1\n",
    "# where the 1s represent BOS, Plus sign, Equal sign, the extra digit in the sum, EOS, respectively.\n",
    "max_len = 3*max_ndigits + 6\n",
    "config = ModelConfig(decoder_vocab_size= vocab_size,\n",
    "                     d_embed=128,\n",
    "                     d_ff=256,\n",
    "                     h=4,\n",
    "                     N_decoder=2,\n",
    "                     max_seq_len= max_len,\n",
    "                     dropout=0.1)\n",
    "dataset_size = 10000\n",
    "data_loaders = DataLoaders(max_ndigits, dataset_size, padQ=True)\n",
    "data_loaders.split_data(split=[1000, 2000])\n",
    "train_size = len(data_loaders.train_loader)*batch_size\n",
    "model = make_GPT(config)\n",
    "model_size = sum([p.numel() for p in model.parameters()])\n",
    "print(f'model_size: {model_size}, train_set_size: {train_size}')\n",
    "warmup_steps = 3*len(data_loaders.train_loader)\n",
    "# lr first increases in the warmup steps, and then descreases\n",
    "lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.2, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "train_loss, val_loss = train(model, data_loaders, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cae6fa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [256, 1, 1, 10], which does not match the required output shape [256, 1, 10, 10]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [208, 1, 1, 10], which does not match the required output shape [208, 1, 10, 10]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 7], which does not match the required output shape [1, 1, 7, 7]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 8], which does not match the required output shape [1, 1, 8, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 9], which does not match the required output shape [1, 1, 9, 9]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 10], which does not match the required output shape [1, 1, 10, 10]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set examples the model gives an incorrect result:\n",
      "validataion set examples the model gives an incorrect result:\n",
      "test set examples the model gives an incorrect result:\n",
      "train_size: 7168, train_loss: 0.008579625598421054,\n",
      "                val_loss: 0.002247950482342276, test_loss: 0.00010329616316084866,\n",
      "                test_acc: 1.0, val_acc: 1.0, train_acc: 1.0\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "test_loss = validate(model, data_loaders.test_loader)\n",
    "print('training set examples the model gives an incorrect result:')\n",
    "train_acc = evaluate(model, data_loaders.train_loader, 20)\n",
    "print('validataion set examples the model gives an incorrect result:')\n",
    "val_acc = evaluate(model, data_loaders.test_loader)\n",
    "print('test set examples the model gives an incorrect result:')\n",
    "test_acc = evaluate(model, data_loaders.test_loader)\n",
    "result = f'''train_size: {train_size}, train_loss: {train_loss},\n",
    "                val_loss: {val_loss}, test_loss: {test_loss},\n",
    "                test_acc: {test_acc}, val_acc: {val_acc}, train_acc: {train_acc}\n",
    "                '''\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb8d5e",
   "metadata": {},
   "source": [
    "no incorrect results were observed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f84208d",
   "metadata": {},
   "source": [
    "# 5 Digit Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aee29daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_size: 272530, train_set_size: 170240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/665 [00:00<?, ?it/s]/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [256, 1, 1, 19], which does not match the required output shape [256, 1, 19, 19]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "ep: 0, train loss=1.606,lr=0.00030:  99%|█████████▉| 658/665 [00:10<00:00, 65.41it/s]/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [16, 1, 1, 19], which does not match the required output shape [16, 1, 19, 19]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "ep: 0, train loss=1.606,lr=0.00030: 100%|██████████| 665/665 [00:10<00:00, 65.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: train_loss: 2.07644, val_loss: 1.54197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 1, train loss=1.298,lr=0.00061: 100%|██████████| 665/665 [00:10<00:00, 65.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: train_loss: 1.47744, val_loss: 1.24604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 2, train loss=0.321,lr=0.00091: 100%|██████████| 665/665 [00:10<00:00, 65.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: train_loss: 0.73744, val_loss: 0.19745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 3, train loss=0.070,lr=0.00122: 100%|██████████| 665/665 [00:10<00:00, 65.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: train_loss: 0.09241, val_loss: 0.02036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 4, train loss=0.035,lr=0.00153: 100%|██████████| 665/665 [00:10<00:00, 65.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: train_loss: 0.04839, val_loss: 0.01729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 5, train loss=0.025,lr=0.00140: 100%|██████████| 665/665 [00:10<00:00, 65.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: train_loss: 0.03925, val_loss: 0.01674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 6, train loss=0.031,lr=0.00130: 100%|██████████| 665/665 [00:10<00:00, 65.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: train_loss: 0.03185, val_loss: 0.01425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 7, train loss=0.034,lr=0.00121: 100%|██████████| 665/665 [00:10<00:00, 65.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: train_loss: 0.02839, val_loss: 0.01523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 8, train loss=0.024,lr=0.00114: 100%|██████████| 665/665 [00:10<00:00, 65.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: train_loss: 0.02501, val_loss: 0.01177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 9, train loss=0.023,lr=0.00108: 100%|██████████| 665/665 [00:10<00:00, 65.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: train_loss: 0.02232, val_loss: 0.01145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 10, train loss=0.026,lr=0.00103: 100%|██████████| 665/665 [00:10<00:00, 65.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: train_loss: 0.02107, val_loss: 0.00966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 11, train loss=0.013,lr=0.00099: 100%|██████████| 665/665 [00:10<00:00, 65.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: train_loss: 0.01902, val_loss: 0.00929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 12, train loss=0.015,lr=0.00095: 100%|██████████| 665/665 [00:10<00:00, 65.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: train_loss: 0.01809, val_loss: 0.00882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 13, train loss=0.020,lr=0.00092: 100%|██████████| 665/665 [00:10<00:00, 64.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: train_loss: 0.01716, val_loss: 0.00806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 14, train loss=0.032,lr=0.00089: 100%|██████████| 665/665 [00:10<00:00, 65.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: train_loss: 0.01634, val_loss: 0.00899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 15, train loss=0.017,lr=0.00086: 100%|██████████| 665/665 [00:10<00:00, 65.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: train_loss: 0.01637, val_loss: 0.00901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 16, train loss=0.012,lr=0.00083: 100%|██████████| 665/665 [00:10<00:00, 65.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: train_loss: 0.01544, val_loss: 0.00883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 17, train loss=0.010,lr=0.00081: 100%|██████████| 665/665 [00:10<00:00, 65.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: train_loss: 0.01457, val_loss: 0.00846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 18, train loss=0.012,lr=0.00079: 100%|██████████| 665/665 [00:10<00:00, 65.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: train_loss: 0.01426, val_loss: 0.00728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 19, train loss=0.018,lr=0.00077: 100%|██████████| 665/665 [00:10<00:00, 65.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: train_loss: 0.01356, val_loss: 0.00768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 20, train loss=0.015,lr=0.00075: 100%|██████████| 665/665 [00:10<00:00, 65.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: train_loss: 0.01340, val_loss: 0.00794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 21, train loss=0.005,lr=0.00073: 100%|██████████| 665/665 [00:10<00:00, 65.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: train_loss: 0.01323, val_loss: 0.00800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 22, train loss=0.012,lr=0.00071: 100%|██████████| 665/665 [00:10<00:00, 65.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: train_loss: 0.01304, val_loss: 0.00715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 23, train loss=0.003,lr=0.00070: 100%|██████████| 665/665 [00:10<00:00, 65.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: train_loss: 0.01234, val_loss: 0.00651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 24, train loss=0.008,lr=0.00069: 100%|██████████| 665/665 [00:10<00:00, 65.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: train_loss: 0.01221, val_loss: 0.00707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 25, train loss=0.008,lr=0.00067: 100%|██████████| 665/665 [00:10<00:00, 65.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: train_loss: 0.01183, val_loss: 0.00620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 26, train loss=0.015,lr=0.00066: 100%|██████████| 665/665 [00:10<00:00, 65.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: train_loss: 0.01114, val_loss: 0.00626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 27, train loss=0.008,lr=0.00065: 100%|██████████| 665/665 [00:10<00:00, 65.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: train_loss: 0.01064, val_loss: 0.00535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 28, train loss=0.008,lr=0.00064: 100%|██████████| 665/665 [00:10<00:00, 65.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: train_loss: 0.00907, val_loss: 0.00360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 29, train loss=0.019,lr=0.00063: 100%|██████████| 665/665 [00:10<00:00, 65.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: train_loss: 0.00781, val_loss: 0.00331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 30, train loss=0.005,lr=0.00062: 100%|██████████| 665/665 [00:10<00:00, 65.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30: train_loss: 0.00735, val_loss: 0.00326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 31, train loss=0.014,lr=0.00061: 100%|██████████| 665/665 [00:10<00:00, 65.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 31: train_loss: 0.00688, val_loss: 0.00323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 32, train loss=0.004,lr=0.00060: 100%|██████████| 665/665 [00:10<00:00, 65.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: train_loss: 0.00681, val_loss: 0.00312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 33, train loss=0.007,lr=0.00059: 100%|██████████| 665/665 [00:10<00:00, 65.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 33: train_loss: 0.00625, val_loss: 0.00322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 34, train loss=0.009,lr=0.00058: 100%|██████████| 665/665 [00:10<00:00, 65.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 34: train_loss: 0.00638, val_loss: 0.00357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 35, train loss=0.002,lr=0.00057: 100%|██████████| 665/665 [00:10<00:00, 65.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 35: train_loss: 0.00602, val_loss: 0.00207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 36, train loss=0.001,lr=0.00056: 100%|██████████| 665/665 [00:10<00:00, 65.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 36: train_loss: 0.00471, val_loss: 0.00084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 37, train loss=0.009,lr=0.00056: 100%|██████████| 665/665 [00:10<00:00, 65.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 37: train_loss: 0.00366, val_loss: 0.00046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 38, train loss=0.001,lr=0.00055: 100%|██████████| 665/665 [00:10<00:00, 64.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 38: train_loss: 0.00331, val_loss: 0.00043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 39, train loss=0.001,lr=0.00054: 100%|██████████| 665/665 [00:10<00:00, 64.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 39: train_loss: 0.00285, val_loss: 0.00030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 40, train loss=0.001,lr=0.00054: 100%|██████████| 665/665 [00:10<00:00, 64.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 40: train_loss: 0.00259, val_loss: 0.00020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 41, train loss=0.001,lr=0.00053: 100%|██████████| 665/665 [00:10<00:00, 64.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 41: train_loss: 0.00253, val_loss: 0.00019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 42, train loss=0.001,lr=0.00052: 100%|██████████| 665/665 [00:10<00:00, 63.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 42: train_loss: 0.00217, val_loss: 0.00010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 43, train loss=0.003,lr=0.00052: 100%|██████████| 665/665 [00:10<00:00, 64.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 43: train_loss: 0.00258, val_loss: 0.00013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 44, train loss=0.001,lr=0.00051: 100%|██████████| 665/665 [00:10<00:00, 64.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 44: train_loss: 0.00214, val_loss: 0.00013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 45, train loss=0.003,lr=0.00051: 100%|██████████| 665/665 [00:10<00:00, 64.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 45: train_loss: 0.00215, val_loss: 0.00014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 46, train loss=0.002,lr=0.00050: 100%|██████████| 665/665 [00:10<00:00, 65.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 46: train_loss: 0.00193, val_loss: 0.00010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 47, train loss=0.000,lr=0.00049: 100%|██████████| 665/665 [00:10<00:00, 65.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 47: train_loss: 0.00204, val_loss: 0.00006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 48, train loss=0.000,lr=0.00049: 100%|██████████| 665/665 [00:10<00:00, 65.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 48: train_loss: 0.00183, val_loss: 0.00005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 49, train loss=0.001,lr=0.00048: 100%|██████████| 665/665 [00:10<00:00, 65.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 49: train_loss: 0.00165, val_loss: 0.00004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 50, train loss=0.001,lr=0.00048: 100%|██████████| 665/665 [00:10<00:00, 65.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 50: train_loss: 0.00173, val_loss: 0.00006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 51, train loss=0.003,lr=0.00048: 100%|██████████| 665/665 [00:10<00:00, 65.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 51: train_loss: 0.00163, val_loss: 0.00003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 52, train loss=0.001,lr=0.00047: 100%|██████████| 665/665 [00:10<00:00, 65.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 52: train_loss: 0.00165, val_loss: 0.00005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 53, train loss=0.000,lr=0.00047: 100%|██████████| 665/665 [00:10<00:00, 65.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 53: train_loss: 0.00148, val_loss: 0.00002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 54, train loss=0.002,lr=0.00046: 100%|██████████| 665/665 [00:10<00:00, 65.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 54: train_loss: 0.00168, val_loss: 0.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 55, train loss=0.001,lr=0.00046: 100%|██████████| 665/665 [00:10<00:00, 65.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 55: train_loss: 0.00155, val_loss: 0.00002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 56, train loss=0.001,lr=0.00045: 100%|██████████| 665/665 [00:10<00:00, 65.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 56: train_loss: 0.00137, val_loss: 0.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 57, train loss=0.000,lr=0.00045: 100%|██████████| 665/665 [00:10<00:00, 62.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 57: train_loss: 0.00129, val_loss: 0.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 58, train loss=0.004,lr=0.00045: 100%|██████████| 665/665 [00:10<00:00, 65.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 58: train_loss: 0.00130, val_loss: 0.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 59, train loss=0.000,lr=0.00044: 100%|██████████| 665/665 [00:10<00:00, 64.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 59: train_loss: 0.00128, val_loss: 0.00006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 60, train loss=0.001,lr=0.00044: 100%|██████████| 665/665 [00:10<00:00, 65.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 60: train_loss: 0.00137, val_loss: 0.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 61, train loss=0.001,lr=0.00044: 100%|██████████| 665/665 [00:10<00:00, 64.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 61: train_loss: 0.00133, val_loss: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 62, train loss=0.000,lr=0.00043: 100%|██████████| 665/665 [00:10<00:00, 64.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 62: train_loss: 0.00123, val_loss: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 63, train loss=0.002,lr=0.00043: 100%|██████████| 665/665 [00:10<00:00, 64.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 63: train_loss: 0.00121, val_loss: 0.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 64, train loss=0.000,lr=0.00043: 100%|██████████| 665/665 [00:10<00:00, 63.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 64: train_loss: 0.00113, val_loss: 0.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 65, train loss=0.001,lr=0.00042: 100%|██████████| 665/665 [00:10<00:00, 64.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 65: train_loss: 0.00132, val_loss: 0.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 66, train loss=0.000,lr=0.00042: 100%|██████████| 665/665 [00:10<00:00, 64.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 66: train_loss: 0.00107, val_loss: 0.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 67, train loss=0.000,lr=0.00042: 100%|██████████| 665/665 [00:10<00:00, 64.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 67: train_loss: 0.00122, val_loss: 0.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 68, train loss=0.000,lr=0.00041: 100%|██████████| 665/665 [00:10<00:00, 64.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 68: train_loss: 0.00110, val_loss: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 69, train loss=0.013,lr=0.00041: 100%|██████████| 665/665 [00:10<00:00, 64.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 69: train_loss: 0.00108, val_loss: 0.00001\n"
     ]
    }
   ],
   "source": [
    "max_ndigits = 5\n",
    "# max_len is determined by 1+ max_ndigits + 1 + max_ndigits + 1 + max_ndigits +1 +1\n",
    "max_len = 3*max_ndigits + 6\n",
    "config = ModelConfig(decoder_vocab_size= vocab_size,\n",
    "                     d_embed=128,\n",
    "                     d_ff=256,\n",
    "                     h=4,\n",
    "                     N_decoder=2,\n",
    "                     max_seq_len= max_len,\n",
    "                     dropout=0.1)\n",
    "\n",
    "dataset_size = 200000\n",
    "data_loaders = DataLoaders(max_ndigits, dataset_size, padQ=True)\n",
    "data_loaders.split_data(split=[10000, 20000])\n",
    "train_size = len(data_loaders.train_loader)*batch_size\n",
    "model = make_GPT(config)\n",
    "model_size = sum([p.numel() for p in model.parameters()])\n",
    "print(f'model_size: {model_size}, train_set_size: {train_size}')\n",
    "warmup_steps = 5*len(data_loaders.train_loader)\n",
    "# lr first increases in the warmup steps, and then descreases\n",
    "lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "train_loss, val_loss = train(model, data_loaders, epochs=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "354d96c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [256, 1, 1, 19], which does not match the required output shape [256, 1, 19, 19]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [32, 1, 1, 19], which does not match the required output shape [32, 1, 19, 19]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 13], which does not match the required output shape [1, 1, 13, 13]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 14], which does not match the required output shape [1, 1, 14, 14]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 15], which does not match the required output shape [1, 1, 15, 15]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 16], which does not match the required output shape [1, 1, 16, 16]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 17], which does not match the required output shape [1, 1, 17, 17]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 18], which does not match the required output shape [1, 1, 18, 18]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 19], which does not match the required output shape [1, 1, 19, 19]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set examples the model gives an incorrect result:\n",
      "validataion set examples the model gives an incorrect result:\n",
      "test set examples the model gives an incorrect result:\n",
      "train_size: 170240, train_loss: 0.0010843980230736334,\n",
      "                val_loss: 1.0287986023627127e-05, test_loss: 3.6189080926213803e-06,\n",
      "                test_acc: 1.0, val_acc: 1.0, train_acc: 1.0\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "test_loss = validate(model, data_loaders.test_loader)\n",
    "print('training set examples the model gives an incorrect result:')\n",
    "train_acc = evaluate(model, data_loaders.train_loader, 20)\n",
    "print('validataion set examples the model gives an incorrect result:')\n",
    "val_acc = evaluate(model, data_loaders.test_loader)\n",
    "print('test set examples the model gives an incorrect result:')\n",
    "test_acc = evaluate(model, data_loaders.test_loader)\n",
    "result = f'''train_size: {train_size}, train_loss: {train_loss},\n",
    "                val_loss: {val_loss}, test_loss: {test_loss},\n",
    "                test_acc: {test_acc}, val_acc: {val_acc}, train_acc: {train_acc}\n",
    "                '''\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b39ac",
   "metadata": {},
   "source": [
    "no incorrect results were observed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf9cbee",
   "metadata": {},
   "source": [
    "# 10 Digit Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88e3cce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_size: 274450, train_set_size: 270080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1055 [00:00<?, ?it/s]/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [256, 1, 1, 34], which does not match the required output shape [256, 1, 34, 34]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "ep: 0, train loss=1.917,lr=0.00024:  99%|█████████▉| 1049/1055 [00:19<00:00, 52.49it/s]/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [176, 1, 1, 34], which does not match the required output shape [176, 1, 34, 34]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "ep: 0, train loss=1.917,lr=0.00024: 100%|██████████| 1055/1055 [00:19<00:00, 53.42it/s]\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [16, 1, 1, 34], which does not match the required output shape [16, 1, 34, 34]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: train_loss: 2.22305, val_loss: 1.88622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 1, train loss=1.678,lr=0.00049: 100%|██████████| 1055/1055 [00:19<00:00, 53.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: train_loss: 1.81938, val_loss: 1.64982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 2, train loss=0.578,lr=0.00073: 100%|██████████| 1055/1055 [00:19<00:00, 52.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: train_loss: 1.12391, val_loss: 0.45079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 3, train loss=0.172,lr=0.00097: 100%|██████████| 1055/1055 [00:19<00:00, 53.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: train_loss: 0.30092, val_loss: 0.08800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 4, train loss=0.118,lr=0.00122: 100%|██████████| 1055/1055 [00:19<00:00, 52.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: train_loss: 0.14321, val_loss: 0.07182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 5, train loss=0.045,lr=0.00111: 100%|██████████| 1055/1055 [00:19<00:00, 52.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: train_loss: 0.08933, val_loss: 0.02312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 6, train loss=0.112,lr=0.00103: 100%|██████████| 1055/1055 [00:19<00:00, 53.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: train_loss: 0.04062, val_loss: 0.01445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 7, train loss=0.021,lr=0.00096: 100%|██████████| 1055/1055 [00:19<00:00, 53.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: train_loss: 0.03002, val_loss: 0.01244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 8, train loss=0.019,lr=0.00091: 100%|██████████| 1055/1055 [00:19<00:00, 53.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: train_loss: 0.02380, val_loss: 0.00946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 9, train loss=0.012,lr=0.00086: 100%|██████████| 1055/1055 [00:19<00:00, 53.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: train_loss: 0.01963, val_loss: 0.00828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 10, train loss=0.016,lr=0.00082: 100%|██████████| 1055/1055 [00:19<00:00, 53.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: train_loss: 0.01762, val_loss: 0.00787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 11, train loss=0.014,lr=0.00079: 100%|██████████| 1055/1055 [00:19<00:00, 53.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: train_loss: 0.01551, val_loss: 0.00801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 12, train loss=0.013,lr=0.00075: 100%|██████████| 1055/1055 [00:19<00:00, 53.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: train_loss: 0.01438, val_loss: 0.00726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 13, train loss=0.021,lr=0.00073: 100%|██████████| 1055/1055 [00:19<00:00, 52.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: train_loss: 0.01352, val_loss: 0.00584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 14, train loss=0.014,lr=0.00070: 100%|██████████| 1055/1055 [00:19<00:00, 52.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: train_loss: 0.01160, val_loss: 0.00518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 15, train loss=0.008,lr=0.00068: 100%|██████████| 1055/1055 [00:19<00:00, 52.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: train_loss: 0.01054, val_loss: 0.00456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 16, train loss=0.008,lr=0.00066: 100%|██████████| 1055/1055 [00:19<00:00, 52.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: train_loss: 0.01004, val_loss: 0.00439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 17, train loss=0.014,lr=0.00064: 100%|██████████| 1055/1055 [00:19<00:00, 52.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: train_loss: 0.00961, val_loss: 0.00498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 18, train loss=0.009,lr=0.00062: 100%|██████████| 1055/1055 [00:19<00:00, 52.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: train_loss: 0.00895, val_loss: 0.00433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 19, train loss=0.008,lr=0.00061: 100%|██████████| 1055/1055 [00:19<00:00, 52.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: train_loss: 0.00912, val_loss: 0.00456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 20, train loss=0.008,lr=0.00059: 100%|██████████| 1055/1055 [00:19<00:00, 52.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: train_loss: 0.00838, val_loss: 0.00459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 21, train loss=0.008,lr=0.00058: 100%|██████████| 1055/1055 [00:19<00:00, 52.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: train_loss: 0.00807, val_loss: 0.00423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 22, train loss=0.010,lr=0.00057: 100%|██████████| 1055/1055 [00:20<00:00, 52.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: train_loss: 0.00779, val_loss: 0.00395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 23, train loss=0.008,lr=0.00056: 100%|██████████| 1055/1055 [00:20<00:00, 52.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: train_loss: 0.00763, val_loss: 0.00400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 24, train loss=0.013,lr=0.00054: 100%|██████████| 1055/1055 [00:19<00:00, 52.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: train_loss: 0.00735, val_loss: 0.00375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 25, train loss=0.007,lr=0.00053: 100%|██████████| 1055/1055 [00:19<00:00, 52.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: train_loss: 0.00740, val_loss: 0.00361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 26, train loss=0.007,lr=0.00052: 100%|██████████| 1055/1055 [00:19<00:00, 52.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: train_loss: 0.00686, val_loss: 0.00362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 27, train loss=0.004,lr=0.00051: 100%|██████████| 1055/1055 [00:20<00:00, 52.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: train_loss: 0.00674, val_loss: 0.00353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 28, train loss=0.008,lr=0.00051: 100%|██████████| 1055/1055 [00:20<00:00, 52.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: train_loss: 0.00665, val_loss: 0.00374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 29, train loss=0.005,lr=0.00050: 100%|██████████| 1055/1055 [00:20<00:00, 52.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: train_loss: 0.00639, val_loss: 0.00355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 30, train loss=0.005,lr=0.00049: 100%|██████████| 1055/1055 [00:19<00:00, 52.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30: train_loss: 0.00643, val_loss: 0.00316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 31, train loss=0.004,lr=0.00048: 100%|██████████| 1055/1055 [00:19<00:00, 52.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 31: train_loss: 0.00637, val_loss: 0.00357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 32, train loss=0.005,lr=0.00047: 100%|██████████| 1055/1055 [00:19<00:00, 52.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: train_loss: 0.00609, val_loss: 0.00314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 33, train loss=0.008,lr=0.00047: 100%|██████████| 1055/1055 [00:20<00:00, 52.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 33: train_loss: 0.00598, val_loss: 0.00289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 34, train loss=0.009,lr=0.00046: 100%|██████████| 1055/1055 [00:20<00:00, 52.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 34: train_loss: 0.00588, val_loss: 0.00283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 35, train loss=0.003,lr=0.00045: 100%|██████████| 1055/1055 [00:20<00:00, 52.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 35: train_loss: 0.00565, val_loss: 0.00259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 36, train loss=0.003,lr=0.00045: 100%|██████████| 1055/1055 [00:19<00:00, 52.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 36: train_loss: 0.00551, val_loss: 0.00248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 37, train loss=0.004,lr=0.00044: 100%|██████████| 1055/1055 [00:20<00:00, 52.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 37: train_loss: 0.00515, val_loss: 0.00290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 38, train loss=0.008,lr=0.00044: 100%|██████████| 1055/1055 [00:20<00:00, 52.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 38: train_loss: 0.00506, val_loss: 0.00285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 39, train loss=0.008,lr=0.00043: 100%|██████████| 1055/1055 [00:19<00:00, 52.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 39: train_loss: 0.00509, val_loss: 0.00205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 40, train loss=0.007,lr=0.00043: 100%|██████████| 1055/1055 [00:20<00:00, 52.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 40: train_loss: 0.00474, val_loss: 0.00219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 41, train loss=0.003,lr=0.00042: 100%|██████████| 1055/1055 [00:20<00:00, 52.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 41: train_loss: 0.00436, val_loss: 0.00237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 42, train loss=0.003,lr=0.00042: 100%|██████████| 1055/1055 [00:19<00:00, 52.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 42: train_loss: 0.00431, val_loss: 0.00183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 43, train loss=0.004,lr=0.00041: 100%|██████████| 1055/1055 [00:20<00:00, 52.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 43: train_loss: 0.00410, val_loss: 0.00167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 44, train loss=0.005,lr=0.00041: 100%|██████████| 1055/1055 [00:19<00:00, 52.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 44: train_loss: 0.00403, val_loss: 0.00191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 45, train loss=0.001,lr=0.00040: 100%|██████████| 1055/1055 [00:20<00:00, 51.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 45: train_loss: 0.00409, val_loss: 0.00166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 46, train loss=0.002,lr=0.00040: 100%|██████████| 1055/1055 [00:20<00:00, 51.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 46: train_loss: 0.00385, val_loss: 0.00175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 47, train loss=0.003,lr=0.00039: 100%|██████████| 1055/1055 [00:19<00:00, 52.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 47: train_loss: 0.00385, val_loss: 0.00209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 48, train loss=0.009,lr=0.00039: 100%|██████████| 1055/1055 [00:20<00:00, 52.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 48: train_loss: 0.00370, val_loss: 0.00164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 49, train loss=0.003,lr=0.00038: 100%|██████████| 1055/1055 [00:20<00:00, 52.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 49: train_loss: 0.00380, val_loss: 0.00177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 50, train loss=0.005,lr=0.00038: 100%|██████████| 1055/1055 [00:19<00:00, 52.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 50: train_loss: 0.00379, val_loss: 0.00158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 51, train loss=0.003,lr=0.00038: 100%|██████████| 1055/1055 [00:19<00:00, 52.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 51: train_loss: 0.00361, val_loss: 0.00167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 52, train loss=0.007,lr=0.00037: 100%|██████████| 1055/1055 [00:20<00:00, 52.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 52: train_loss: 0.00361, val_loss: 0.00164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 53, train loss=0.003,lr=0.00037: 100%|██████████| 1055/1055 [00:19<00:00, 52.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 53: train_loss: 0.00353, val_loss: 0.00157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 54, train loss=0.005,lr=0.00037: 100%|██████████| 1055/1055 [00:19<00:00, 52.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 54: train_loss: 0.00341, val_loss: 0.00176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 55, train loss=0.004,lr=0.00036: 100%|██████████| 1055/1055 [00:19<00:00, 52.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 55: train_loss: 0.00340, val_loss: 0.00143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 56, train loss=0.006,lr=0.00036: 100%|██████████| 1055/1055 [00:19<00:00, 52.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 56: train_loss: 0.00335, val_loss: 0.00164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 57, train loss=0.002,lr=0.00036: 100%|██████████| 1055/1055 [00:19<00:00, 53.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 57: train_loss: 0.00321, val_loss: 0.00135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 58, train loss=0.002,lr=0.00035: 100%|██████████| 1055/1055 [00:20<00:00, 52.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 58: train_loss: 0.00348, val_loss: 0.00139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 59, train loss=0.001,lr=0.00035: 100%|██████████| 1055/1055 [00:20<00:00, 52.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 59: train_loss: 0.00327, val_loss: 0.00180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 60, train loss=0.002,lr=0.00035: 100%|██████████| 1055/1055 [00:19<00:00, 52.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 60: train_loss: 0.00332, val_loss: 0.00133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 61, train loss=0.004,lr=0.00035: 100%|██████████| 1055/1055 [00:19<00:00, 52.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 61: train_loss: 0.00322, val_loss: 0.00136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 62, train loss=0.003,lr=0.00034: 100%|██████████| 1055/1055 [00:19<00:00, 52.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 62: train_loss: 0.00318, val_loss: 0.00126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 63, train loss=0.004,lr=0.00034: 100%|██████████| 1055/1055 [00:19<00:00, 53.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 63: train_loss: 0.00320, val_loss: 0.00149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 64, train loss=0.003,lr=0.00034: 100%|██████████| 1055/1055 [00:20<00:00, 52.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 64: train_loss: 0.00303, val_loss: 0.00146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 65, train loss=0.001,lr=0.00033: 100%|██████████| 1055/1055 [00:20<00:00, 52.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 65: train_loss: 0.00300, val_loss: 0.00127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 66, train loss=0.004,lr=0.00033: 100%|██████████| 1055/1055 [00:19<00:00, 52.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 66: train_loss: 0.00301, val_loss: 0.00117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 67, train loss=0.003,lr=0.00033: 100%|██████████| 1055/1055 [00:20<00:00, 52.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 67: train_loss: 0.00301, val_loss: 0.00165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 68, train loss=0.005,lr=0.00033: 100%|██████████| 1055/1055 [00:20<00:00, 52.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 68: train_loss: 0.00296, val_loss: 0.00143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 69, train loss=0.002,lr=0.00033: 100%|██████████| 1055/1055 [00:20<00:00, 52.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 69: train_loss: 0.00318, val_loss: 0.00123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 70, train loss=0.002,lr=0.00032: 100%|██████████| 1055/1055 [00:20<00:00, 51.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 70: train_loss: 0.00282, val_loss: 0.00120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 71, train loss=0.003,lr=0.00032: 100%|██████████| 1055/1055 [00:20<00:00, 52.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 71: train_loss: 0.00287, val_loss: 0.00118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 72, train loss=0.002,lr=0.00032: 100%|██████████| 1055/1055 [00:20<00:00, 52.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 72: train_loss: 0.00283, val_loss: 0.00127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 73, train loss=0.005,lr=0.00032: 100%|██████████| 1055/1055 [00:20<00:00, 51.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 73: train_loss: 0.00284, val_loss: 0.00136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 74, train loss=0.002,lr=0.00031: 100%|██████████| 1055/1055 [00:19<00:00, 53.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 74: train_loss: 0.00278, val_loss: 0.00123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 75, train loss=0.005,lr=0.00031: 100%|██████████| 1055/1055 [00:19<00:00, 53.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 75: train_loss: 0.00284, val_loss: 0.00132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 76, train loss=0.004,lr=0.00031: 100%|██████████| 1055/1055 [00:19<00:00, 53.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 76: train_loss: 0.00281, val_loss: 0.00117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 77, train loss=0.002,lr=0.00031: 100%|██████████| 1055/1055 [00:19<00:00, 53.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 77: train_loss: 0.00273, val_loss: 0.00131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 78, train loss=0.002,lr=0.00031: 100%|██████████| 1055/1055 [00:19<00:00, 53.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 78: train_loss: 0.00276, val_loss: 0.00165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 79, train loss=0.004,lr=0.00030: 100%|██████████| 1055/1055 [00:19<00:00, 53.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 79: train_loss: 0.00271, val_loss: 0.00145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 80, train loss=0.004,lr=0.00030: 100%|██████████| 1055/1055 [00:19<00:00, 53.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 80: train_loss: 0.00264, val_loss: 0.00106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 81, train loss=0.001,lr=0.00030: 100%|██████████| 1055/1055 [00:19<00:00, 53.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 81: train_loss: 0.00277, val_loss: 0.00130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 82, train loss=0.003,lr=0.00030: 100%|██████████| 1055/1055 [00:19<00:00, 53.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 82: train_loss: 0.00266, val_loss: 0.00123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 83, train loss=0.002,lr=0.00030: 100%|██████████| 1055/1055 [00:20<00:00, 52.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 83: train_loss: 0.00266, val_loss: 0.00116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 84, train loss=0.001,lr=0.00030: 100%|██████████| 1055/1055 [00:20<00:00, 52.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 84: train_loss: 0.00268, val_loss: 0.00105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 89, train loss=0.000,lr=0.00029: 100%|██████████| 1055/1055 [00:19<00:00, 53.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 89: train_loss: 0.00253, val_loss: 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 90, train loss=0.001,lr=0.00029: 100%|██████████| 1055/1055 [00:19<00:00, 53.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 90: train_loss: 0.00262, val_loss: 0.00123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 91, train loss=0.004,lr=0.00028: 100%|██████████| 1055/1055 [00:20<00:00, 52.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 91: train_loss: 0.00245, val_loss: 0.00111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 92, train loss=0.002,lr=0.00028: 100%|██████████| 1055/1055 [00:19<00:00, 53.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 92: train_loss: 0.00252, val_loss: 0.00121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 93, train loss=0.001,lr=0.00028: 100%|██████████| 1055/1055 [00:19<00:00, 53.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 93: train_loss: 0.00243, val_loss: 0.00111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 94, train loss=0.001,lr=0.00028: 100%|██████████| 1055/1055 [00:19<00:00, 53.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 94: train_loss: 0.00268, val_loss: 0.00114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 95, train loss=0.001,lr=0.00028: 100%|██████████| 1055/1055 [00:19<00:00, 53.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 95: train_loss: 0.00233, val_loss: 0.00142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 96, train loss=0.001,lr=0.00028: 100%|██████████| 1055/1055 [00:19<00:00, 53.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 96: train_loss: 0.00237, val_loss: 0.00113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 97, train loss=0.002,lr=0.00027: 100%|██████████| 1055/1055 [00:19<00:00, 53.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 97: train_loss: 0.00241, val_loss: 0.00096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 98, train loss=0.005,lr=0.00027: 100%|██████████| 1055/1055 [00:19<00:00, 53.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 98: train_loss: 0.00244, val_loss: 0.00124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 99, train loss=0.003,lr=0.00027: 100%|██████████| 1055/1055 [00:20<00:00, 52.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 99: train_loss: 0.00237, val_loss: 0.00124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 100, train loss=0.002,lr=0.00027: 100%|██████████| 1055/1055 [00:20<00:00, 52.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 100: train_loss: 0.00242, val_loss: 0.00108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 101, train loss=0.002,lr=0.00027: 100%|██████████| 1055/1055 [00:20<00:00, 52.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 101: train_loss: 0.00239, val_loss: 0.00135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 102, train loss=0.002,lr=0.00027: 100%|██████████| 1055/1055 [00:19<00:00, 53.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 102: train_loss: 0.00234, val_loss: 0.00117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 103, train loss=0.002,lr=0.00027: 100%|██████████| 1055/1055 [00:19<00:00, 53.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 103: train_loss: 0.00232, val_loss: 0.00099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 104, train loss=0.001,lr=0.00027: 100%|██████████| 1055/1055 [00:19<00:00, 53.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 104: train_loss: 0.00229, val_loss: 0.00114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 105, train loss=0.001,lr=0.00026: 100%|██████████| 1055/1055 [00:19<00:00, 53.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 105: train_loss: 0.00233, val_loss: 0.00117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 106, train loss=0.002,lr=0.00026: 100%|██████████| 1055/1055 [00:19<00:00, 53.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 106: train_loss: 0.00222, val_loss: 0.00105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 107, train loss=0.001,lr=0.00026: 100%|██████████| 1055/1055 [00:19<00:00, 53.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 107: train_loss: 0.00226, val_loss: 0.00112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 108, train loss=0.004,lr=0.00026: 100%|██████████| 1055/1055 [00:19<00:00, 53.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 108: train_loss: 0.00220, val_loss: 0.00089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 109, train loss=0.001,lr=0.00026: 100%|██████████| 1055/1055 [00:19<00:00, 53.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 109: train_loss: 0.00228, val_loss: 0.00093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 110, train loss=0.001,lr=0.00026: 100%|██████████| 1055/1055 [00:19<00:00, 53.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 110: train_loss: 0.00224, val_loss: 0.00093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 111, train loss=0.002,lr=0.00026: 100%|██████████| 1055/1055 [00:19<00:00, 53.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 111: train_loss: 0.00223, val_loss: 0.00083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 112, train loss=0.001,lr=0.00026: 100%|██████████| 1055/1055 [00:20<00:00, 52.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 112: train_loss: 0.00225, val_loss: 0.00083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 113, train loss=0.004,lr=0.00025: 100%|██████████| 1055/1055 [00:19<00:00, 52.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 113: train_loss: 0.00222, val_loss: 0.00115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 114, train loss=0.002,lr=0.00025: 100%|██████████| 1055/1055 [00:19<00:00, 53.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 114: train_loss: 0.00223, val_loss: 0.00107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 115, train loss=0.003,lr=0.00025: 100%|██████████| 1055/1055 [00:19<00:00, 53.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 115: train_loss: 0.00214, val_loss: 0.00097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 116, train loss=0.001,lr=0.00025: 100%|██████████| 1055/1055 [00:19<00:00, 53.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 116: train_loss: 0.00205, val_loss: 0.00111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 117, train loss=0.001,lr=0.00025: 100%|██████████| 1055/1055 [00:19<00:00, 53.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 117: train_loss: 0.00223, val_loss: 0.00091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 118, train loss=0.002,lr=0.00025: 100%|██████████| 1055/1055 [00:19<00:00, 53.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 118: train_loss: 0.00217, val_loss: 0.00089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 119, train loss=0.001,lr=0.00025: 100%|██████████| 1055/1055 [00:19<00:00, 53.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 119: train_loss: 0.00214, val_loss: 0.00073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 120, train loss=0.005,lr=0.00025: 100%|██████████| 1055/1055 [00:19<00:00, 53.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 120: train_loss: 0.00213, val_loss: 0.00081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 121, train loss=0.008,lr=0.00025: 100%|██████████| 1055/1055 [00:19<00:00, 53.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 121: train_loss: 0.00203, val_loss: 0.00107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 122, train loss=0.001,lr=0.00025: 100%|██████████| 1055/1055 [00:19<00:00, 53.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 122: train_loss: 0.00220, val_loss: 0.00074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 123, train loss=0.002,lr=0.00024: 100%|██████████| 1055/1055 [00:20<00:00, 52.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 123: train_loss: 0.00204, val_loss: 0.00092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 124, train loss=0.002,lr=0.00024: 100%|██████████| 1055/1055 [00:20<00:00, 52.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 124: train_loss: 0.00197, val_loss: 0.00074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 125, train loss=0.000,lr=0.00024: 100%|██████████| 1055/1055 [00:19<00:00, 52.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 125: train_loss: 0.00197, val_loss: 0.00075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 126, train loss=0.003,lr=0.00024: 100%|██████████| 1055/1055 [00:20<00:00, 52.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 126: train_loss: 0.00198, val_loss: 0.00070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 127, train loss=0.002,lr=0.00024: 100%|██████████| 1055/1055 [00:19<00:00, 53.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 127: train_loss: 0.00185, val_loss: 0.00072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 128, train loss=0.001,lr=0.00024: 100%|██████████| 1055/1055 [00:19<00:00, 52.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 128: train_loss: 0.00186, val_loss: 0.00060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 129, train loss=0.004,lr=0.00024: 100%|██████████| 1055/1055 [00:20<00:00, 52.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 129: train_loss: 0.00197, val_loss: 0.00076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 130, train loss=0.002,lr=0.00024: 100%|██████████| 1055/1055 [00:20<00:00, 52.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 130: train_loss: 0.00189, val_loss: 0.00063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 131, train loss=0.004,lr=0.00024: 100%|██████████| 1055/1055 [00:19<00:00, 52.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 131: train_loss: 0.00170, val_loss: 0.00070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 132, train loss=0.003,lr=0.00024: 100%|██████████| 1055/1055 [00:20<00:00, 52.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 132: train_loss: 0.00161, val_loss: 0.00041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 133, train loss=0.004,lr=0.00024: 100%|██████████| 1055/1055 [00:20<00:00, 52.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 133: train_loss: 0.00158, val_loss: 0.00030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 134, train loss=0.001,lr=0.00023: 100%|██████████| 1055/1055 [00:19<00:00, 52.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 134: train_loss: 0.00149, val_loss: 0.00027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 135, train loss=0.001,lr=0.00023: 100%|██████████| 1055/1055 [00:20<00:00, 52.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 135: train_loss: 0.00131, val_loss: 0.00035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 136, train loss=0.000,lr=0.00023: 100%|██████████| 1055/1055 [00:20<00:00, 52.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 136: train_loss: 0.00115, val_loss: 0.00035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 137, train loss=0.003,lr=0.00023: 100%|██████████| 1055/1055 [00:20<00:00, 52.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 137: train_loss: 0.00115, val_loss: 0.00024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 138, train loss=0.000,lr=0.00023: 100%|██████████| 1055/1055 [00:20<00:00, 52.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 138: train_loss: 0.00112, val_loss: 0.00020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 139, train loss=0.001,lr=0.00023: 100%|██████████| 1055/1055 [00:20<00:00, 52.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 139: train_loss: 0.00106, val_loss: 0.00025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 140, train loss=0.003,lr=0.00023: 100%|██████████| 1055/1055 [00:20<00:00, 52.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 140: train_loss: 0.00109, val_loss: 0.00022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 141, train loss=0.003,lr=0.00023: 100%|██████████| 1055/1055 [00:20<00:00, 52.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 141: train_loss: 0.00109, val_loss: 0.00026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 142, train loss=0.000,lr=0.00023: 100%|██████████| 1055/1055 [00:19<00:00, 53.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 142: train_loss: 0.00097, val_loss: 0.00023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 143, train loss=0.003,lr=0.00023: 100%|██████████| 1055/1055 [00:19<00:00, 53.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 143: train_loss: 0.00106, val_loss: 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 144, train loss=0.002,lr=0.00023: 100%|██████████| 1055/1055 [00:19<00:00, 52.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 144: train_loss: 0.00100, val_loss: 0.00019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 145, train loss=0.000,lr=0.00023: 100%|██████████| 1055/1055 [00:19<00:00, 53.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 145: train_loss: 0.00093, val_loss: 0.00024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 146, train loss=0.000,lr=0.00022: 100%|██████████| 1055/1055 [00:19<00:00, 53.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 146: train_loss: 0.00107, val_loss: 0.00026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 147, train loss=0.000,lr=0.00022: 100%|██████████| 1055/1055 [00:19<00:00, 52.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 147: train_loss: 0.00093, val_loss: 0.00018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 148, train loss=0.001,lr=0.00022: 100%|██████████| 1055/1055 [00:19<00:00, 52.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 148: train_loss: 0.00098, val_loss: 0.00017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 149, train loss=0.000,lr=0.00022: 100%|██████████| 1055/1055 [00:19<00:00, 53.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 149: train_loss: 0.00086, val_loss: 0.00023\n"
     ]
    }
   ],
   "source": [
    "max_ndigits = 10\n",
    "# max_len is determined by 1+ max_ndigits + 1 + max_ndigits + 1 + max_ndigits +1 +1\n",
    "max_len = 3*max_ndigits + 6\n",
    "config = ModelConfig(decoder_vocab_size= vocab_size,\n",
    "                     d_embed=128,\n",
    "                     d_ff=256,\n",
    "                     h=4,\n",
    "                     N_decoder=2,\n",
    "                     max_seq_len= max_len,\n",
    "                     dropout=0.1)\n",
    "dataset_size = 300000\n",
    "data_loaders = DataLoaders(max_ndigits, dataset_size, padQ=True)\n",
    "data_loaders.split_data(split=[10000, 20000])\n",
    "train_size = len(data_loaders.train_loader)*batch_size\n",
    "model = make_GPT(config)\n",
    "model_size = sum([p.numel() for p in model.parameters()])\n",
    "print(f'model_size: {model_size}, train_set_size: {train_size}')\n",
    "warmup_steps = 5*len(data_loaders.train_loader)\n",
    "# lr first increases in the warmup steps, and then descreases\n",
    "lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "train_loss, val_loss = train(model, data_loaders, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db5e56e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [256, 1, 1, 34], which does not match the required output shape [256, 1, 34, 34]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [32, 1, 1, 34], which does not match the required output shape [32, 1, 34, 34]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 23], which does not match the required output shape [1, 1, 23, 23]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 24], which does not match the required output shape [1, 1, 24, 24]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 25], which does not match the required output shape [1, 1, 25, 25]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 26], which does not match the required output shape [1, 1, 26, 26]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 27], which does not match the required output shape [1, 1, 27, 27]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 28], which does not match the required output shape [1, 1, 28, 28]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 29], which does not match the required output shape [1, 1, 29, 29]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 30], which does not match the required output shape [1, 1, 30, 30]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 31], which does not match the required output shape [1, 1, 31, 31]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 32], which does not match the required output shape [1, 1, 32, 32]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 33], which does not match the required output shape [1, 1, 33, 33]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [1, 1, 1, 34], which does not match the required output shape [1, 1, 34, 34]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set examples the model gives an incorrect result:\n",
      "correct equation: 5986250995+1651849091=7638100086\n",
      "predicted:        5986250995+1651849091=7638000086\n",
      "correct equation: 6220698785+3774201250=9994900035\n",
      "predicted:        6220698785+3774201250=9994800035\n",
      "correct equation: 1479270551+2482219449=3961490000\n",
      "predicted:        1479270551+2482219449=3961480000\n",
      "validataion set examples the model gives an incorrect result:\n",
      "correct equation: 1429344373+4270655709=5700000082\n",
      "predicted:        1429344373+4270655709=5699000082\n",
      "correct equation: 2974793598+0568206458=3543000056\n",
      "predicted:        2974793598+0568206458=3543900056\n",
      "correct equation: 1991526364+9108473724=11100000088\n",
      "predicted:        1991526364+9108473724=11000000088\n",
      "correct equation: 5446176784+3754473218=9200650002\n",
      "predicted:        5446176784+3754473218=9200640002\n",
      "correct equation: 8134374390+9895622045=18029996435\n",
      "predicted:        8134374390+9895622045=18039996435\n",
      "test set examples the model gives an incorrect result:\n",
      "correct equation: 6646304646+3236695988=9883000634\n",
      "predicted:        6646304646+3236695988=9882000634\n",
      "correct equation: 1991526364+9108473724=11100000088\n",
      "predicted:        1991526364+9108473724=11000000088\n",
      "correct equation: 7283299490+1702500556=8985800046\n",
      "predicted:        7283299490+1702500556=8985700046\n",
      "correct equation: 1159064279+1607485721=2766550000\n",
      "predicted:        1159064279+1607485721=2766540000\n",
      "correct equation: 1539305991+9309694035=10849000026\n",
      "predicted:        1539305991+9309694035=10848000026\n",
      "train_size: 270080, train_loss: 0.0008610427818269087,\n",
      "                val_loss: 0.00023498593335951056, test_loss: 0.00015081095918533926,\n",
      "                test_acc: 0.99935, val_acc: 0.99935, train_acc: 0.9994673295454546\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "test_loss = validate(model, data_loaders.test_loader)\n",
    "print('training set examples the model gives an incorrect result:')\n",
    "train_acc = evaluate(model, data_loaders.train_loader, 20)\n",
    "print('validataion set examples the model gives an incorrect result:')\n",
    "val_acc = evaluate(model, data_loaders.test_loader)\n",
    "print('test set examples the model gives an incorrect result:')\n",
    "test_acc = evaluate(model, data_loaders.test_loader)\n",
    "result = f'''train_size: {train_size}, train_loss: {train_loss},\n",
    "                val_loss: {val_loss}, test_loss: {test_loss},\n",
    "                test_acc: {test_acc}, val_acc: {val_acc}, train_acc: {train_acc}\n",
    "                '''\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f65e8f",
   "metadata": {},
   "source": [
    "minute single digit variation was observed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8796b607",
   "metadata": {},
   "source": [
    "# 18 Digit Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_size: 277522, train_set_size: 370176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1446 [00:00<?, ?it/s]/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [256, 1, 1, 58], which does not match the required output shape [256, 1, 58, 58]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "ep: 0, train loss=2.081,lr=0.00020: 100%|█████████▉| 1445/1446 [00:36<00:00, 39.51it/s]/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [80, 1, 1, 58], which does not match the required output shape [80, 1, 58, 58]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
      "ep: 0, train loss=2.081,lr=0.00020: 100%|██████████| 1446/1446 [00:36<00:00, 39.79it/s]\n",
      "/scratch/local/ipykernel_11738/3920961143.py:67: UserWarning: An output with one or more elements was resized since it had shape [16, 1, 1, 58], which does not match the required output shape [16, 1, 58, 58]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: train_loss: 2.28385, val_loss: 2.05867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 1, train loss=2.011,lr=0.00041: 100%|██████████| 1446/1446 [00:36<00:00, 39.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: train_loss: 2.03676, val_loss: 1.99809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 2, train loss=1.727,lr=0.00062: 100%|██████████| 1446/1446 [00:36<00:00, 39.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: train_loss: 1.88767, val_loss: 1.63243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 3, train loss=0.289,lr=0.00083: 100%|██████████| 1446/1446 [00:36<00:00, 39.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: train_loss: 0.88012, val_loss: 0.17052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 4, train loss=0.094,lr=0.00103: 100%|██████████| 1446/1446 [00:36<00:00, 40.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: train_loss: 0.15666, val_loss: 0.02681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 5, train loss=0.044,lr=0.00095: 100%|██████████| 1446/1446 [00:36<00:00, 39.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: train_loss: 0.06800, val_loss: 0.01589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 6, train loss=0.041,lr=0.00088: 100%|██████████| 1446/1446 [00:36<00:00, 39.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: train_loss: 0.04235, val_loss: 0.01189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 7, train loss=0.024,lr=0.00082: 100%|██████████| 1446/1446 [00:36<00:00, 39.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: train_loss: 0.03190, val_loss: 0.01222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 8, train loss=0.026,lr=0.00078: 100%|██████████| 1446/1446 [00:36<00:00, 39.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: train_loss: 0.02600, val_loss: 0.00905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 9, train loss=0.021,lr=0.00074: 100%|██████████| 1446/1446 [00:36<00:00, 39.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: train_loss: 0.02160, val_loss: 0.00786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 10, train loss=0.013,lr=0.00070: 100%|██████████| 1446/1446 [00:36<00:00, 39.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: train_loss: 0.01825, val_loss: 0.00675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 11, train loss=0.012,lr=0.00067: 100%|██████████| 1446/1446 [00:36<00:00, 39.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: train_loss: 0.01638, val_loss: 0.00654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 12, train loss=0.017,lr=0.00065: 100%|██████████| 1446/1446 [00:36<00:00, 40.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: train_loss: 0.01457, val_loss: 0.00560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 13, train loss=0.013,lr=0.00062: 100%|██████████| 1446/1446 [00:36<00:00, 39.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: train_loss: 0.01326, val_loss: 0.00526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 14, train loss=0.009,lr=0.00060: 100%|██████████| 1446/1446 [00:36<00:00, 40.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: train_loss: 0.01214, val_loss: 0.00467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 15, train loss=0.013,lr=0.00058: 100%|██████████| 1446/1446 [00:36<00:00, 39.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: train_loss: 0.01127, val_loss: 0.00510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 16, train loss=0.012,lr=0.00056: 100%|██████████| 1446/1446 [00:36<00:00, 39.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: train_loss: 0.01075, val_loss: 0.00498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 17, train loss=0.011,lr=0.00055: 100%|██████████| 1446/1446 [00:36<00:00, 40.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: train_loss: 0.01022, val_loss: 0.00466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 18, train loss=0.007,lr=0.00053: 100%|██████████| 1446/1446 [00:36<00:00, 39.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: train_loss: 0.00997, val_loss: 0.00432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 19, train loss=0.006,lr=0.00052: 100%|██████████| 1446/1446 [00:36<00:00, 39.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: train_loss: 0.00947, val_loss: 0.00473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 20, train loss=0.013,lr=0.00051: 100%|██████████| 1446/1446 [00:36<00:00, 39.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: train_loss: 0.00914, val_loss: 0.00437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 21, train loss=0.007,lr=0.00050: 100%|██████████| 1446/1446 [00:36<00:00, 39.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: train_loss: 0.00888, val_loss: 0.00422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 22, train loss=0.006,lr=0.00048: 100%|██████████| 1446/1446 [00:36<00:00, 39.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: train_loss: 0.00853, val_loss: 0.00415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 23, train loss=0.005,lr=0.00047: 100%|██████████| 1446/1446 [00:36<00:00, 39.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: train_loss: 0.00832, val_loss: 0.00401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 24, train loss=0.011,lr=0.00047: 100%|██████████| 1446/1446 [00:36<00:00, 40.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: train_loss: 0.00806, val_loss: 0.00395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 25, train loss=0.010,lr=0.00046: 100%|██████████| 1446/1446 [00:36<00:00, 39.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: train_loss: 0.00787, val_loss: 0.00419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 26, train loss=0.012,lr=0.00045: 100%|██████████| 1446/1446 [00:36<00:00, 40.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: train_loss: 0.00768, val_loss: 0.00398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 27, train loss=0.010,lr=0.00044: 100%|██████████| 1446/1446 [00:36<00:00, 39.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: train_loss: 0.00757, val_loss: 0.00365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 28, train loss=0.010,lr=0.00043: 100%|██████████| 1446/1446 [00:36<00:00, 39.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: train_loss: 0.00734, val_loss: 0.00427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 29, train loss=0.009,lr=0.00042: 100%|██████████| 1446/1446 [00:36<00:00, 39.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: train_loss: 0.00720, val_loss: 0.00360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 30, train loss=0.005,lr=0.00042: 100%|██████████| 1446/1446 [00:36<00:00, 39.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30: train_loss: 0.00709, val_loss: 0.00394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 31, train loss=0.007,lr=0.00041: 100%|██████████| 1446/1446 [00:36<00:00, 39.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 31: train_loss: 0.00697, val_loss: 0.00375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 32, train loss=0.011,lr=0.00040: 100%|██████████| 1446/1446 [00:36<00:00, 39.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: train_loss: 0.00682, val_loss: 0.00359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 33, train loss=0.008,lr=0.00040: 100%|██████████| 1446/1446 [00:36<00:00, 39.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 33: train_loss: 0.00676, val_loss: 0.00395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 34, train loss=0.010,lr=0.00039: 100%|██████████| 1446/1446 [00:36<00:00, 39.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 34: train_loss: 0.00662, val_loss: 0.00375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 35, train loss=0.005,lr=0.00039: 100%|██████████| 1446/1446 [00:36<00:00, 39.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 35: train_loss: 0.00646, val_loss: 0.00386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 36, train loss=0.006,lr=0.00038: 100%|██████████| 1446/1446 [00:36<00:00, 39.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 36: train_loss: 0.00639, val_loss: 0.00380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 37, train loss=0.006,lr=0.00038: 100%|██████████| 1446/1446 [00:36<00:00, 39.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 37: train_loss: 0.00637, val_loss: 0.00376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 38, train loss=0.008,lr=0.00037: 100%|██████████| 1446/1446 [00:36<00:00, 39.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 38: train_loss: 0.00616, val_loss: 0.00319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 39, train loss=0.008,lr=0.00037: 100%|██████████| 1446/1446 [00:36<00:00, 39.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 39: train_loss: 0.00602, val_loss: 0.00332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 40, train loss=0.004,lr=0.00036: 100%|██████████| 1446/1446 [00:36<00:00, 39.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 40: train_loss: 0.00594, val_loss: 0.00345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 41, train loss=0.007,lr=0.00036: 100%|██████████| 1446/1446 [00:36<00:00, 39.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 41: train_loss: 0.00586, val_loss: 0.00301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 42, train loss=0.003,lr=0.00035: 100%|██████████| 1446/1446 [00:36<00:00, 39.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 42: train_loss: 0.00595, val_loss: 0.00375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 43, train loss=0.003,lr=0.00035: 100%|██████████| 1446/1446 [00:36<00:00, 39.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 43: train_loss: 0.00576, val_loss: 0.00375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 44, train loss=0.004,lr=0.00035: 100%|██████████| 1446/1446 [00:36<00:00, 39.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 44: train_loss: 0.00570, val_loss: 0.00304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 45, train loss=0.007,lr=0.00034: 100%|██████████| 1446/1446 [00:35<00:00, 40.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 45: train_loss: 0.00559, val_loss: 0.00341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 46, train loss=0.005,lr=0.00034: 100%|██████████| 1446/1446 [00:35<00:00, 40.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 46: train_loss: 0.00555, val_loss: 0.00313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 47, train loss=0.005,lr=0.00034: 100%|██████████| 1446/1446 [00:35<00:00, 40.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 47: train_loss: 0.00552, val_loss: 0.00333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 48, train loss=0.008,lr=0.00033: 100%|██████████| 1446/1446 [00:35<00:00, 40.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 48: train_loss: 0.00547, val_loss: 0.00290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 49, train loss=0.003,lr=0.00033: 100%|██████████| 1446/1446 [00:35<00:00, 40.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 49: train_loss: 0.00538, val_loss: 0.00292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 50, train loss=0.005,lr=0.00033: 100%|██████████| 1446/1446 [00:35<00:00, 40.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 50: train_loss: 0.00533, val_loss: 0.00335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 51, train loss=0.005,lr=0.00032: 100%|██████████| 1446/1446 [00:35<00:00, 40.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 51: train_loss: 0.00536, val_loss: 0.00364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 52, train loss=0.003,lr=0.00032: 100%|██████████| 1446/1446 [00:36<00:00, 40.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 52: train_loss: 0.00527, val_loss: 0.00297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 53, train loss=0.005,lr=0.00032: 100%|██████████| 1446/1446 [00:36<00:00, 39.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 53: train_loss: 0.00518, val_loss: 0.00319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 54, train loss=0.009,lr=0.00031: 100%|██████████| 1446/1446 [00:36<00:00, 39.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 54: train_loss: 0.00514, val_loss: 0.00465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 55, train loss=0.004,lr=0.00031: 100%|██████████| 1446/1446 [00:36<00:00, 40.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 55: train_loss: 0.00511, val_loss: 0.00311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 56, train loss=0.006,lr=0.00031: 100%|██████████| 1446/1446 [00:36<00:00, 39.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 56: train_loss: 0.00505, val_loss: 0.00305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 57, train loss=0.006,lr=0.00031: 100%|██████████| 1446/1446 [00:36<00:00, 40.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 57: train_loss: 0.00500, val_loss: 0.00412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 58, train loss=0.004,lr=0.00030: 100%|██████████| 1446/1446 [00:36<00:00, 40.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 58: train_loss: 0.00504, val_loss: 0.00328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 59, train loss=0.003,lr=0.00030: 100%|██████████| 1446/1446 [00:36<00:00, 39.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 59: train_loss: 0.00493, val_loss: 0.00281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 60, train loss=0.003,lr=0.00030:  50%|█████     | 726/1446 [00:18<00:18, 39.52it/s]"
     ]
    }
   ],
   "source": [
    "max_ndigits = 18\n",
    "# max_len is determined by 1+ max_ndigits + 1 + max_ndigits + 1 + max_ndigits +1 +1\n",
    "max_len = 3*max_ndigits + 6\n",
    "config = ModelConfig(decoder_vocab_size= vocab_size,\n",
    "                     d_embed=128,\n",
    "                     d_ff=256,\n",
    "                     h=4,\n",
    "                     N_decoder=2,\n",
    "                     max_seq_len= max_len,\n",
    "                     dropout=0.1)\n",
    "dataset_size = 400000\n",
    "data_loaders = DataLoaders(max_ndigits, dataset_size, padQ=True)\n",
    "data_loaders.split_data(split=[10000, 20000])\n",
    "train_size = len(data_loaders.train_loader)*batch_size\n",
    "model = make_GPT(config)\n",
    "model_size = sum([p.numel() for p in model.parameters()])\n",
    "print(f'model_size: {model_size}, train_set_size: {train_size}')\n",
    "warmup_steps = 5*len(data_loaders.train_loader)\n",
    "# lr first increases in the warmup steps, and then decreases\n",
    "lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "train_loss, val_loss = train(model, data_loaders, epochs=150)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
